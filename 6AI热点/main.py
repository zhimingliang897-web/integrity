import os
import json
import html
import requests
import feedparser
from openai import OpenAI
from datetime import datetime, timezone, timedelta
from pathlib import Path

# --- é…ç½® ---
QWEN_API_KEY = os.getenv("QWEN_API_KEY")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID", "-1003878273027")
MODEL_NAME = "qwen3-vl-flash-2026-01-22"
TARGET_COUNT = 10  # æ¯å¤©å›ºå®šæ¨é€ 10 æ¡

BJ_TZ = timezone(timedelta(hours=8))
DOCS_DIR = Path(__file__).resolve().parent.parent / "docs"
DATA_DIR = DOCS_DIR / "data"

client = OpenAI(
    api_key=QWEN_API_KEY,
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
)

# --- ä¿¡æºåˆ—è¡¨ ---
SOURCES = [
    # ===== å›½é™…ç¡¬æ ¸ =====
    {"name": "Hacker News", "url": "https://hnrss.org/newest?q=AI+LLM+Transformer+GPT", "type": "general", "count": 8},
    {"name": "HF Papers", "url": "https://rsshub.app/huggingface/daily-papers", "type": "general", "count": 8},
    {"name": "GitHub Trending", "url": "https://rsshub.app/github/trending/daily/python?since=daily", "type": "general", "count": 6},
    {"name": "ArXiv cs.AI", "url": "https://rss.arxiv.org/rss/cs.AI", "type": "general", "count": 6},
    {"name": "ArXiv cs.CL", "url": "https://rss.arxiv.org/rss/cs.CL", "type": "general", "count": 6},
    # ===== å›½é™…ç¤¾åŒº =====
    {"name": "Reddit LocalLLaMA", "url": "https://www.reddit.com/r/LocalLLaMA/.rss", "type": "general", "count": 6},
    {"name": "Reddit ML", "url": "https://www.reddit.com/r/MachineLearning/.rss", "type": "general", "count": 6},
    {"name": "OpenAI Blog", "url": "https://rsshub.app/openai/blog", "type": "general", "count": 5},
    {"name": "Google AI", "url": "https://rsshub.app/google/research", "type": "general", "count": 5},
    {"name": "MIT Tech Review", "url": "https://www.technologyreview.com/feed/", "type": "general", "count": 5},
    # ===== å›½å†…æƒå¨ =====
    {"name": "æœºå™¨ä¹‹å¿ƒ", "url": "https://www.jiqizhixin.com/rss", "type": "cn_media", "count": 6},
    {"name": "é‡å­ä½", "url": "https://rsshub.app/qbitai/category/èµ„è®¯", "type": "cn_media", "count": 6},
]


# ============================================================
# LLM è°ƒç”¨
# ============================================================

def call_qwen(prompt: str) -> str | None:
    try:
        resp = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[{"role": "user", "content": prompt}],
        )
        return resp.choices[0].message.content
    except Exception as e:
        print(f"[Qwen API Error] {e}")
        return None


def analyze_news(title: str, summary: str, source_type: str) -> dict | None:
    anti_hype = ""
    if source_type == "cn_media":
        anti_hype = (
            "æ³¨æ„ï¼šæœ¬æ–‡æ¥è‡ªä¸­æ–‡è‡ªåª’ä½“ï¼Œè¯·é€‚å½“å¿½ç•¥'ç‚¸è£‚''é¢ è¦†''ç¥ä½œ'ç­‰è¥é”€è¯æ±‡ï¼Œ"
            "ä¾§é‡å…³æ³¨æ˜¯å¦æœ‰ä»£ç /è®ºæ–‡/å®è´¨æŠ€æœ¯å†…å®¹ã€‚ä½†å¦‚æœåº•å±‚å†…å®¹ç¡®å®æœ‰ä»·å€¼ï¼Œä¸è¦å› ä¸ºæ ‡é¢˜å¤¸å¼ å°±é™åˆ†ã€‚"
        )

    prompt = f"""ä½ æ˜¯ä¸€ä½ AI æŠ€æœ¯æƒ…æŠ¥åˆ†æå¸ˆï¼Œè´Ÿè´£ä¸ºæŠ€æœ¯ä»ä¸šè€…ç­›é€‰æ¯æ—¥å€¼å¾—å…³æ³¨çš„å†…å®¹ã€‚
{anti_hype}

è¯·åˆ†æä»¥ä¸‹æ–°é—»ï¼š
æ ‡é¢˜ï¼š{title}
æ‘˜è¦ï¼š{summary}

è¯„çº§æ ‡å‡†ï¼ˆè¯·åˆç†ç»™åˆ†ï¼Œä¸è¦è¿‡äºè‹›åˆ»ï¼‰ï¼š
- Sçº§ (9-10): è¡Œä¸šé‡Œç¨‹ç¢‘äº‹ä»¶ã€é¢ è¦†æ€§æ¶æ„çªç ´ã€é‡é‡çº§äº§å“å‘å¸ƒã€‚
- Açº§ (7-8): é«˜è´¨é‡è®ºæ–‡ã€å®ç”¨å·¥å…·é‡å¤§æ›´æ–°ã€å¤§å‚é‡è¦å¼€æºã€å€¼å¾—å…³æ³¨çš„è¡Œä¸šåŠ¨æ€ã€‚
- Bçº§ (5-6): æœ‰ä¸€å®šå‚è€ƒä»·å€¼çš„å†…å®¹ã€ä¸­ç­‰è´¨é‡çš„æŠ€æœ¯åˆ†äº«ã€æ™®é€šäº§å“è¿­ä»£ã€‚
- Cçº§ (1-4): çº¯æ°´æ–‡ã€æ— å®è´¨å†…å®¹çš„å…¬å…³ç¨¿ã€é‡å¤æ—§é—»ã€‚

è¯·åªè¾“å‡ºä¸€ä¸ªåˆæ³• JSONï¼Œä¸è¦åŒ…å« Markdown ä»£ç å—æ ‡è®°ï¼š
{{"rating":"S/A/B/C","score":æ•´æ•°1åˆ°10,"comment":"ä¸€å¥è¯ç‚¹è¯„(ä¸­æ–‡,20å­—å†…)","tags":["æ ‡ç­¾1","æ ‡ç­¾2"]}}"""

    text = call_qwen(prompt)
    if not text:
        return None

    clean = text.replace("```json", "").replace("```", "").strip()
    start = clean.find("{")
    end = clean.rfind("}") + 1
    if start == -1 or end == 0:
        print(f"[JSON æå–å¤±è´¥] {title}")
        return None
    try:
        return json.loads(clean[start:end])
    except json.JSONDecodeError:
        print(f"[JSON è§£æå¤±è´¥] {title}")
        return None


# ============================================================
# æ•°æ®é‡‡é›†
# ============================================================

def fetch_source(source: dict) -> list[dict]:
    name = source["name"]
    count = source.get("count", 5)
    print(f">> æ­£åœ¨æŠ“å–: {name} ...")
    try:
        feed = feedparser.parse(source["url"])
    except Exception as e:
        print(f"[RSS æŠ“å–å¤±è´¥] {name}: {e}")
        return []

    if not feed.entries:
        print(f"   (æ— å†…å®¹)")
        return []

    results = []
    for entry in feed.entries[:count]:
        title = getattr(entry, "title", "").strip()
        summary = getattr(entry, "summary", "")[:800]
        link = getattr(entry, "link", "")
        if not title:
            continue

        analysis = analyze_news(title, summary, source["type"])
        if not analysis:
            continue

        rating = analysis.get("rating", "C")
        score = analysis.get("score", 0)
        results.append({
            "source": name,
            "title": title,
            "link": link,
            "rating": rating,
            "score": score,
            "comment": analysis.get("comment", ""),
            "tags": analysis.get("tags", []),
        })
        print(f"   [{rating}|{score}] {title}")

    return results


def select_top_news(all_news: list[dict]) -> list[dict]:
    all_news.sort(key=lambda x: x["score"], reverse=True)

    seen = set()
    unique = []
    for item in all_news:
        key = item["title"].lower().strip()
        if key not in seen:
            seen.add(key)
            unique.append(item)

    # å–å‰ TARGET_COUNT æ¡ï¼ˆä¸å†åŒºåˆ†ç­‰çº§ï¼Œç›´æ¥æŒ‰åˆ†æ•°æ’ï¼‰
    selected = unique[:TARGET_COUNT]
    return selected


# ============================================================
# LLM ç”Ÿæˆæ€»ç»“
# ============================================================

def generate_summary(news_list: list[dict]) -> str:
    headlines = "\n".join(
        [f"- [{n['rating']}|{n['score']}] {n['title']}" for n in news_list]
    )
    prompt = f"""ä½ æ˜¯ä¸€ä½ AI é¢†åŸŸæƒ…æŠ¥ç¼–è¾‘ã€‚ä»¥ä¸‹æ˜¯ä»Šå¤©ç­›é€‰å‡ºçš„ AI æ–°é—»æ ‡é¢˜åˆ—è¡¨ï¼š

{headlines}

è¯·ç”¨ä¸­æ–‡å†™ 2-3 å¥è¯çš„ã€Œä»Šæ—¥æ¦‚è§ˆã€ï¼Œæ¦‚æ‹¬ä»Šå¤©æœ€å€¼å¾—å…³æ³¨çš„æ–¹å‘ã€‚
è¦æ±‚ï¼šç®€æ´ã€æœ‰æ´å¯ŸåŠ›ã€ä¸è¶…è¿‡ 80 å­—ï¼Œä¸è¦ç”¨ Markdown æ ¼å¼ã€‚"""

    result = call_qwen(prompt)
    return result.strip() if result else "ä»Šæ—¥ AI é¢†åŸŸåŠ¨æ€æ±‡æ€»å¦‚ä¸‹ã€‚"


# ============================================================
# Telegram æ¨é€
# ============================================================

def build_telegram_report(news_list: list[dict], summary: str) -> str:
    today = datetime.now(BJ_TZ).strftime("%Y-%m-%d")
    lines = []

    lines.append(f"<b>ğŸ“¡ AI æƒ…æŠ¥ | {today}</b>")
    lines.append(f"<i>{summary}</i>")
    lines.append("")

    for i, item in enumerate(news_list, 1):
        badge = {"S": "ğŸ”´S", "A": "ğŸŸ A"}.get(item["rating"], "ğŸŸ¡B")
        tags = " ".join([f"#{t}" for t in item["tags"]]) if item["tags"] else ""
        title_escaped = html.escape(item["title"])
        comment_escaped = html.escape(item["comment"])

        lines.append(f"<b>{i}. {title_escaped}</b>")
        lines.append(f"  {badge}Â·{item['score']}åˆ† | {item['source']}")
        lines.append(f"  {comment_escaped}")
        if tags:
            lines.append(f"  {tags}")
        lines.append(f"  <a href='{item['link']}'>åŸæ–‡</a>")
        lines.append("")

    return "\n".join(lines)


def send_telegram(text: str):
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    max_len = 3800

    paragraphs = text.split("\n\n")
    chunks = []
    current = ""
    for para in paragraphs:
        if len(current) + len(para) + 2 > max_len:
            if current:
                chunks.append(current)
            current = para
        else:
            current = current + "\n\n" + para if current else para
    if current:
        chunks.append(current)

    for chunk in chunks:
        payload = {
            "chat_id": TELEGRAM_CHAT_ID,
            "text": chunk,
            "parse_mode": "HTML",
            "disable_web_page_preview": True,
        }
        try:
            resp = requests.post(url, json=payload, timeout=30)
            if resp.status_code != 200:
                print(f"[Telegram å‘é€å¤±è´¥] {resp.text}")
        except Exception as e:
            print(f"[Telegram ç½‘ç»œé”™è¯¯] {e}")


# ============================================================
# æ•°æ®å­˜æ¡£ + ç½‘é¡µ
# ============================================================

def save_daily_json(news_list: list[dict], summary: str):
    """ä¿å­˜å½“å¤©æ•°æ®ä¸º JSON æ–‡ä»¶"""
    DATA_DIR.mkdir(parents=True, exist_ok=True)
    today = datetime.now(BJ_TZ).strftime("%Y-%m-%d")
    data = {
        "date": today,
        "summary": summary,
        "news": news_list,
    }
    (DATA_DIR / f"{today}.json").write_text(
        json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8"
    )

    # æ›´æ–°æ—¥æœŸç´¢å¼•æ–‡ä»¶ï¼ˆåˆ—å‡ºæ‰€æœ‰å¯ç”¨æ—¥æœŸï¼‰
    dates = sorted(
        [f.stem for f in DATA_DIR.glob("*.json") if f.stem != "index"],
        reverse=True,
    )
    (DATA_DIR / "index.json").write_text(
        json.dumps(dates, ensure_ascii=False), encoding="utf-8"
    )
    print(f"æ•°æ®å·²å­˜æ¡£: {DATA_DIR / f'{today}.json'}ï¼ˆå…± {len(dates)} å¤©è®°å½•ï¼‰")


# ============================================================
# ä¸»æµç¨‹
# ============================================================

def main():
    print("=== AI æ¯æ—¥æƒ…æŠ¥ Agent å¯åŠ¨ ===\n")
    all_news = []
    for src in SOURCES:
        all_news.extend(fetch_source(src))

    print(f"\nå…±æŠ“å–å¹¶è¯„çº§ {len(all_news)} æ¡å†…å®¹")

    selected = select_top_news(all_news)
    if not selected:
        print("ä»Šæ—¥æ— å€¼å¾—æ¨é€çš„å†…å®¹ã€‚")
        return

    print(f"ç­›é€‰å‡º {len(selected)} æ¡æ¨é€å†…å®¹ï¼Œæ­£åœ¨ç”Ÿæˆæ€»ç»“ ...")

    summary = generate_summary(selected)
    print(f"ä»Šæ—¥æ¦‚è§ˆ: {summary}\n")

    # Telegram æ¨é€
    tg_report = build_telegram_report(selected, summary)
    print("æ­£åœ¨æ¨é€ Telegram ...")
    send_telegram(tg_report)
    print("Telegram æ¨é€å®Œæˆã€‚")

    # ä¿å­˜ JSON æ•°æ®å­˜æ¡£
    save_daily_json(selected, summary)
    print("å…¨éƒ¨å®Œæˆã€‚")


if __name__ == "__main__":
    main()
